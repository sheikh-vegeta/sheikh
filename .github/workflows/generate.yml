name: ğŸš€ Advanced Gemini Batch Prompt Runner (HITL Ready)

on:
  workflow_dispatch:
    inputs:
      model_version:
        description: 'Gemini Model Version'
        required: true
        default: 'gemini-1.5-pro'
        type: choice
        options:
          - 'gemini-1.5-pro'
          - 'gemini-1.5-flash'
          - 'gemini-1.0-pro'
      batch_size:
        description: 'Batch Processing Size'
        required: false
        default: '5'
        type: string
      temperature:
        description: 'Temperature (0.0-2.0)'
        required: false
        default: '0.7'
        type: string
      max_tokens:
        description: 'Max Output Tokens'
        required: false
        default: '8192'
        type: string
      prompt_filter:
        description: 'Process only prompts matching pattern (regex)'
        required: false
        default: '.*'
        type: string
      skip_validation:
        description: 'Skip output validation'
        required: false
        default: false
        type: boolean
  push:
    branches:
      - main
      - develop
    paths:
      - 'python/sheikh.py'
      - 'prompts/**/*.mdx'
      - 'prompts/**/*.md'
  schedule:
    - cron: '0 2 * * 1'  # Weekly runs on Monday 2 AM UTC

env:
  PYTHON_VERSION: '3.11'
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

jobs:
  validate-inputs:
    name: ğŸ” Validate Configuration
    runs-on: ubuntu-latest
    outputs:
      model_version: ${{ steps.config.outputs.model_version }}
      batch_size: ${{ steps.config.outputs.batch_size }}
      temperature: ${{ steps.config.outputs.temperature }}
      max_tokens: ${{ steps.config.outputs.max_tokens }}
      prompt_filter: ${{ steps.config.outputs.prompt_filter }}
      skip_validation: ${{ steps.config.outputs.skip_validation }}
    steps:
      - name: ğŸ“‹ Set Configuration
        id: config
        run: |
          echo "model_version=${{ github.event.inputs.model_version || 'gemini-1.5-pro' }}" >> $GITHUB_OUTPUT
          echo "batch_size=${{ github.event.inputs.batch_size || '5' }}" >> $GITHUB_OUTPUT
          echo "temperature=${{ github.event.inputs.temperature || '0.7' }}" >> $GITHUB_OUTPUT
          echo "max_tokens=${{ github.event.inputs.max_tokens || '8192' }}" >> $GITHUB_OUTPUT
          echo "prompt_filter=${{ github.event.inputs.prompt_filter || '.*' }}" >> $GITHUB_OUTPUT
          echo "skip_validation=${{ github.event.inputs.skip_validation || 'false' }}" >> $GITHUB_OUTPUT

  pre-flight-check:
    name: ğŸ›¡ï¸ Pre-flight Security & Health Check
    runs-on: ubuntu-latest
    needs: validate-inputs
    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2
      
      - name: ğŸ”’ Verify API Key
        run: |
          if [ -z "$GEMINI_API_KEY" ]; then
            echo "âŒ GEMINI_API_KEY secret not found"
            exit 1
          fi
          echo "âœ… API Key configured"
      
      - name: ğŸ“‚ Check Prompt Directory
        run: |
          if [ ! -d "prompts" ]; then
            echo "âŒ Prompts directory not found"
            exit 1
          fi
          
          prompt_count=$(find prompts -name "*.mdx" -o -name "*.md" | wc -l)
          echo "ğŸ“Š Found $prompt_count prompt files"
          
          if [ "$prompt_count" -eq 0 ]; then
            echo "âš ï¸ No prompt files found"
            exit 1
          fi
          
          echo "prompt_count=$prompt_count" >> $GITHUB_ENV
      
      - name: ğŸ§ª Validate Python Script
        run: |
          if [ ! -f "python/sheikh.py" ]; then
            echo "âŒ sheikh.py not found"
            exit 1
          fi
          
          # Check for basic Python syntax
          python -m py_compile python/sheikh.py || {
            echo "âŒ Python syntax validation failed"
            exit 1
          }
          
          echo "âœ… Python script validated"

  generate-prompts:
    name: ğŸ§  Generate Responses (${{ needs.validate-inputs.outputs.model_version }})
    runs-on: ubuntu-latest
    needs: [validate-inputs, pre-flight-check]
    strategy:
      matrix:
        batch: [1, 2, 3, 4, 5]
      fail-fast: false
      max-parallel: 2
    
    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4
      
      - name: ğŸ Setup Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-generativeai python-dotenv tenacity rich click
          pip install -r requirements.txt 2>/dev/null || echo "No requirements.txt found"
      
      - name: ğŸ“‹ Prepare Batch Processing
        id: batch-prep
        run: |
          # Create output directory with timestamp
          timestamp=$(date +"%Y%m%d_%H%M%S")
          output_dir="output/batch_${{ matrix.batch }}_${timestamp}"
          mkdir -p "$output_dir"
          echo "output_dir=$output_dir" >> $GITHUB_OUTPUT
          
          # Get prompt files for this batch
          batch_size=${{ needs.validate-inputs.outputs.batch_size }}
          filter_pattern="${{ needs.validate-inputs.outputs.prompt_filter }}"
          
          # Find and filter prompt files
          all_prompts=$(find prompts -name "*.mdx" -o -name "*.md" | grep -E "$filter_pattern" | sort)
          total_prompts=$(echo "$all_prompts" | wc -l)
          
          # Calculate batch range
          start_idx=$(( (${{ matrix.batch }} - 1) * batch_size + 1 ))
          end_idx=$(( ${{ matrix.batch }} * batch_size ))
          
          if [ $start_idx -gt $total_prompts ]; then
            echo "skip_batch=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          batch_prompts=$(echo "$all_prompts" | sed -n "${start_idx},${end_idx}p")
          echo "$batch_prompts" > batch_files.txt
          
          echo "âœ… Batch ${{ matrix.batch }}: Processing $(echo "$batch_prompts" | wc -l) files"
          echo "skip_batch=false" >> $GITHUB_OUTPUT
      
      - name: ğŸŒ€ Process Batch Prompts
        if: steps.batch-prep.outputs.skip_batch == 'false'
        env:
          MODEL_VERSION: ${{ needs.validate-inputs.outputs.model_version }}
          TEMPERATURE: ${{ needs.validate-inputs.outputs.temperature }}
          MAX_TOKENS: ${{ needs.validate-inputs.outputs.max_tokens }}
          OUTPUT_DIR: ${{ steps.batch-prep.outputs.output_dir }}
        run: |
          success_count=0
          error_count=0
          
          while IFS= read -r file; do
            if [ -z "$file" ]; then continue; fi
            
            filename=$(basename -- "$file")
            name="${filename%.*}"
            output_file="$OUTPUT_DIR/${name}.txt"
            
            echo "ğŸ”„ Processing: $filename"
            
            # Process with timeout and retry logic
            if timeout 300s python python/sheikh.py \
              --model "$MODEL_VERSION" \
              --temperature "$TEMPERATURE" \
              --max-tokens "$MAX_TOKENS" \
              --input "$file" \
              --output "$output_file" 2>&1; then
              
              echo "âœ… Success: $filename"
              success_count=$((success_count + 1))
              
              # Add metadata
              echo "" >> "$output_file"
              echo "---" >> "$output_file"
              echo "Generated: $(date -Iseconds)" >> "$output_file"
              echo "Model: $MODEL_VERSION" >> "$output_file"
              echo "Temperature: $TEMPERATURE" >> "$output_file"
              echo "Source: $file" >> "$output_file"
            else
              echo "âŒ Failed: $filename"
              error_count=$((error_count + 1))
              
              # Create error file
              echo "Error processing $file at $(date -Iseconds)" > "$OUTPUT_DIR/${name}_ERROR.txt"
              echo "Check logs for details" >> "$OUTPUT_DIR/${name}_ERROR.txt"
            fi
            
            # Rate limiting
            sleep 2
          done < batch_files.txt
          
          echo "ğŸ“Š Batch ${{ matrix.batch }} Complete: $success_count successes, $error_count errors"
          echo "batch_success_count=$success_count" >> $GITHUB_ENV
          echo "batch_error_count=$error_count" >> $GITHUB_ENV
      
      - name: ğŸ§¹ Post-process Outputs
        if: steps.batch-prep.outputs.skip_batch == 'false'
        run: |
          output_dir="${{ steps.batch-prep.outputs.output_dir }}"
          
          # Generate batch summary
          cat > "$output_dir/BATCH_SUMMARY.md" << EOF
          # Batch ${{ matrix.batch }} Summary
          
          **Generated:** $(date -Iseconds)
          **Model:** ${{ needs.validate-inputs.outputs.model_version }}
          **Temperature:** ${{ needs.validate-inputs.outputs.temperature }}
          **Max Tokens:** ${{ needs.validate-inputs.outputs.max_tokens }}
          
          ## Statistics
          - âœ… Successful: ${{ env.batch_success_count }}
          - âŒ Errors: ${{ env.batch_error_count }}
          
          ## Files Generated
          EOF
          
          find "$output_dir" -name "*.txt" -not -name "*_ERROR.txt" | sort >> "$output_dir/BATCH_SUMMARY.md"
          
          # Create file index
          ls -lah "$output_dir"
      
      - name: ğŸ“¤ Upload Batch Artifacts
        if: steps.batch-prep.outputs.skip_batch == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: gemini-batch-${{ matrix.batch }}-outputs
          path: ${{ steps.batch-prep.outputs.output_dir }}
          retention-days: 30

  human-review:
    name: ğŸ‘ï¸ Human-in-the-Loop Review
    runs-on: ubuntu-latest
    needs: [validate-inputs, generate-prompts]
    if: always() && needs.generate-prompts.result != 'cancelled'
    
    steps:
      - name: ğŸ“¥ Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: gemini-batch-*-outputs
          path: ./all-outputs
          merge-multiple: true
      
      - name: ğŸ“Š Generate Consolidated Report
        run: |
          mkdir -p review
          
          # Create comprehensive review report
          cat > review/REVIEW_REPORT.md << EOF
          # ğŸ§  Gemini Batch Processing Review Report
          
          **Generated:** $(date -Iseconds)
          **Workflow Run:** ${{ github.run_number }}
          **Triggered by:** ${{ github.event_name }}
          **Model Used:** ${{ needs.validate-inputs.outputs.model_version }}
          
          ## Configuration
          - **Temperature:** ${{ needs.validate-inputs.outputs.temperature }}
          - **Max Tokens:** ${{ needs.validate-inputs.outputs.max_tokens }}
          - **Batch Size:** ${{ needs.validate-inputs.outputs.batch_size }}
          - **Prompt Filter:** \`${{ needs.validate-inputs.outputs.prompt_filter }}\`
          
          ## Processing Summary
          EOF
          
          # Count outputs and errors
          total_outputs=$(find all-outputs -name "*.txt" -not -name "*_ERROR.txt" | wc -l)
          total_errors=$(find all-outputs -name "*_ERROR.txt" | wc -l)
          
          echo "- ğŸ“„ **Total Outputs Generated:** $total_outputs" >> review/REVIEW_REPORT.md
          echo "- âŒ **Total Errors:** $total_errors" >> review/REVIEW_REPORT.md
          echo "" >> review/REVIEW_REPORT.md
          
          # Sample outputs for review
          echo "## ğŸ“‹ Sample Outputs (First 100 chars)" >> review/REVIEW_REPORT.md
          echo "" >> review/REVIEW_REPORT.md
          
          find all-outputs -name "*.txt" -not -name "*_ERROR.txt" | head -5 | while read -r file; do
            echo "### $(basename "$file")" >> review/REVIEW_REPORT.md
            echo '```' >> review/REVIEW_REPORT.md
            head -c 100 "$file" >> review/REVIEW_REPORT.md
            echo '...' >> review/REVIEW_REPORT.md
            echo '```' >> review/REVIEW_REPORT.md
            echo "" >> review/REVIEW_REPORT.md
          done
          
          # Error summary
          if [ $total_errors -gt 0 ]; then
            echo "## âš ï¸ Error Summary" >> review/REVIEW_REPORT.md
            find all-outputs -name "*_ERROR.txt" | while read -r error_file; do
              echo "- $(basename "$error_file")" >> review/REVIEW_REPORT.md
            done
          fi
          
          echo "ğŸ“‹ Review report generated"
      
      - name: ğŸ” Quality Check
        if: needs.validate-inputs.outputs.skip_validation == 'false'
        run: |
          echo "ğŸ§ª Running quality checks..."
          
          # Check for empty outputs
          empty_files=$(find all-outputs -name "*.txt" -not -name "*_ERROR.txt" -empty | wc -l)
          
          # Check for suspiciously short outputs (< 50 chars)
          short_files=$(find all-outputs -name "*.txt" -not -name "*_ERROR.txt" -exec sh -c 'test $(wc -c < "$1") -lt 50' _ {} \; -print | wc -l)
          
          echo "âš ï¸ Empty files: $empty_files"
          echo "âš ï¸ Suspiciously short files: $short_files"
          
          if [ $empty_files -gt 0 ] || [ $short_files -gt 3 ]; then
            echo "ğŸš¨ Quality check concerns detected"
            echo "quality_concerns=true" >> $GITHUB_ENV
          else
            echo "âœ… Quality check passed"
            echo "quality_concerns=false" >> $GITHUB_ENV
          fi
      
      - name: ğŸ“¤ Upload Review Package
        uses: actions/upload-artifact@v4
        with:
          name: human-review-package
          path: |
            review/
            all-outputs/
          retention-days: 7
      
      - name: ğŸ“¢ Slack Notification
        if: env.SLACK_WEBHOOK_URL != ''
        run: |
          quality_status="${{ env.quality_concerns == 'true' && 'ğŸš¨ Quality Concerns' || 'âœ… All Good' }}"
          
          curl -X POST -H 'Content-type: application/json' \
            --data "{
              \"text\": \"ğŸ§  Gemini Batch Processing Complete\",
              \"blocks\": [
                {
                  \"type\": \"section\",
                  \"text\": {
                    \"type\": \"mrkdwn\",
                    \"text\": \"*Gemini Batch Processing Results*\nâ€¢ Model: ${{ needs.validate-inputs.outputs.model_version }}\nâ€¢ Quality: $quality_status\nâ€¢ <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>\"
                  }
                }
              ]
            }" \
            $SLACK_WEBHOOK_URL

  cleanup:
    name: ğŸ§¹ Cleanup & Finalize
    runs-on: ubuntu-latest
    needs: [human-review]
    if: always()
    
    steps:
      - name: ğŸ“Š Final Statistics
        run: |
          echo "ğŸ¯ Workflow completed successfully"
          echo "ğŸ“… Run ID: ${{ github.run_id }}"
          echo "ğŸ”— View results: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
